{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Este notebook realiza un análisis exploratorio completo de nuestro conjunto de datos. Examinaremos las características básicas del dataset, la distribución de la variable objetivo, las relaciones entre variables numéricas y categóricas, y realizaremos visualizaciones para mejor comprensión de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías\n",
    "\n",
    "Comenzamos importando las bibliotecas necesarias para nuestro análisis. Utilizaremos pandas para manipulación de datos, numpy para operaciones numéricas, y matplotlib junto con seaborn para visualizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración para visualizaciones más atractivas\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Análisis Básico de Datos\n",
    "\n",
    "En esta sección, cargaremos nuestro dataset y realizaremos un análisis básico para entender su estructura, dimensiones y características generales. Examinaremos la presencia de valores nulos y obtendremos estadísticas descriptivas básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../data/raw/dataset.csv')\n",
    "\n",
    "def analisis_basico(df):\n",
    "    print(\"Dimensiones del dataset:\", df.shape)\n",
    "    print(\"Información del dataset:\")\n",
    "    print(df.info())\n",
    "    print(\"Estadísticas descriptivas:\")\n",
    "    print(df.describe())\n",
    "    print(\"Valores nulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "analisis_basico(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpieza de Datos\n",
    "En esta sección realizamos la limpieza inicial de los datos, tratando valores nulos y anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_datos(df):\n",
    "    # Crear una copia para no modificar los datos originales\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Identificar columnas numéricas y categóricas\n",
    "    columnas_numericas = df_clean.select_dtypes(include=['float64', 'int64']).columns\n",
    "    columnas_categoricas = df_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Tratar valores nulos en columnas numéricas\n",
    "    imputer_num = SimpleImputer(strategy='median')\n",
    "    df_clean[columnas_numericas] = imputer_num.fit_transform(df_clean[columnas_numericas])\n",
    "    \n",
    "    # Tratar valores nulos en columnas categóricas\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "    df_clean[columnas_categoricas] = imputer_cat.fit_transform(df_clean[columnas_categoricas])\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar limpieza\n",
    "df_limpio = limpiar_datos(df)\n",
    "\n",
    "# Verificar que no hay valores nulos\n",
    "print(\"Valores nulos después de la limpieza:\")\n",
    "display(df_limpio.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento de Datos\n",
    "Aquí realizamos las transformaciones necesarias para preparar los datos para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_datos(df):\n",
    "    \"\"\"\n",
    "    Realiza el preprocesamiento con codificación binaria para variables categóricas\n",
    "    y mantiene el target como 0, 1, 2\n",
    "    \"\"\"\n",
    "    df_proc = df.copy()\n",
    "    \n",
    "    # Primero codificamos el target de manera simple (0, 1, 2)\n",
    "    target_mapping = {\n",
    "        'Dropout': 0,\n",
    "        'Graduate': 1,\n",
    "        'Enrolled': 2\n",
    "    }\n",
    "    df_proc['Target'] = df_proc['Target'].map(target_mapping)\n",
    "    \n",
    "    # Convertir variables categóricas a binarias (one-hot encoding)\n",
    "    categoricas = df_proc.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Aplicar one-hot encoding a todas las variables categóricas\n",
    "    df_proc = pd.get_dummies(df_proc, columns=categoricas, drop_first=True)\n",
    "    \n",
    "    # Normalizar variables numéricas\n",
    "    scaler = StandardScaler()\n",
    "    numericas = df_proc.select_dtypes(include=['float64', 'int64']).columns\n",
    "    numericas = numericas.drop('Target') if 'Target' in numericas else numericas\n",
    "    df_proc[numericas] = scaler.fit_transform(df_proc[numericas])\n",
    "    \n",
    "    # Verificar la codificación del target\n",
    "    print(\"\\nCodificación del Target:\")\n",
    "    print(\"0: Dropout (Abandono)\")\n",
    "    print(\"1: Graduate (Graduado)\")\n",
    "    print(\"2: Enrolled (Matriculado)\")\n",
    "    \n",
    "    # Mostrar distribución de clases\n",
    "    print(\"\\nDistribución de clases después del preprocesamiento:\")\n",
    "    print(df_proc['Target'].value_counts().sort_index().to_frame().join(\n",
    "        df_proc['Target'].value_counts(normalize=True).sort_index().mul(100).round(2).astype(str).add('%').to_frame(\n",
    "            name='Porcentaje'\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Mostrar las nuevas características binarias creadas\n",
    "    print(\"\\nNuevas características binarias creadas:\")\n",
    "    columnas_binarias = [col for col in df_proc.columns if col not in numericas and col != 'Target']\n",
    "    print(columnas_binarias)\n",
    "    \n",
    "    return df_proc\n",
    "\n",
    "# Aplicar limpieza y preprocesamiento\n",
    "df_limpio = limpiar_datos(df)\n",
    "df_procesado = preprocesar_datos(df_limpio)\n",
    "\n",
    "# Guardar dataset procesado\n",
    "df_procesado.to_csv('../data/processed/dataset_procesado.csv', index=False)\n",
    "print(\"\\nDataset procesado guardado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de la Variable Objetivo\n",
    "\n",
    "Analizaremos la distribución de nuestra variable objetivo (Target). Es crucial entender si las clases están balanceadas o si existe un desequilibrio que debamos considerar en nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_target(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    target_counts = df['Target'].value_counts()\n",
    "    sns.barplot(x=target_counts.index, y=target_counts.values)\n",
    "    plt.title('Distribución de la Variable Objetivo')\n",
    "    plt.xlabel('Clase')\n",
    "    plt.ylabel('Cantidad')\n",
    "    plt.show()\n",
    "\n",
    "analisis_target(df)\n",
    "\n",
    "# Mostrar porcentajes de cada clase\n",
    "print(\"Porcentaje de cada clase:\")\n",
    "print(df['Target'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis de Variables Numéricas\n",
    "\n",
    "Examinaremos la distribución de nuestras variables numéricas mediante histogramas y analizaremos las correlaciones entre ellas. Esto nos ayudará a identificar patrones y relaciones importantes en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_numericas(df):\n",
    "    numericas = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Histogramas\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, col in enumerate(numericas[:9], 1):\n",
    "        plt.subplot(3, 3, i)\n",
    "        sns.histplot(data=df, x=col, kde=True)\n",
    "        plt.title(f'Distribución de {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Matriz de correlación\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(df[numericas].corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Matriz de Correlación - Variables Numéricas')\n",
    "    plt.show()\n",
    "\n",
    "analisis_numericas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis de Variables Categóricas\n",
    "\n",
    "Para las variables categóricas, analizaremos su distribución y frecuencia. Esto nos ayudará a identificar categorías dominantes y posibles valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_categoricas(df):\n",
    "    categoricas = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categoricas:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=df, x=col)\n",
    "        plt.title(f'Distribución de {col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "        \n",
    "        # Mostrar frecuencias y porcentajes\n",
    "        print(f\"Distribución de {col}:\")\n",
    "        print(df[col].value_counts().to_frame().join(\n",
    "            df[col].value_counts(normalize=True).mul(100).round(2).astype(str).add('%').to_frame(\n",
    "                name='Porcentaje'\n",
    "            )\n",
    "        ))\n",
    "\n",
    "analisis_categoricas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis Bivariado con Target\n",
    "\n",
    "Finalmente, analizaremos la relación entre nuestras variables numéricas y la variable objetivo mediante box plots. Esto nos ayudará a identificar qué variables podrían ser más importantes para la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_bivariado(df):\n",
    "    numericas = df.select_dtypes(include=['float64', 'int64']).columns[:5]\n",
    "    \n",
    "    # Box plots para variables numéricas vs Target\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, col in enumerate(numericas, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.boxplot(data=df, x='Target', y=col)\n",
    "        plt.title(f'{col} vs Target')\n",
    "        plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analisis_bivariado(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Análisis de Correlaciones\n",
    "Finalmente, analizamos las correlaciones entre variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de correlación\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_limpio.select_dtypes(include=['float64', 'int64']).corr(), \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0)\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Variables Seleccionadas para Modelado\n",
    "### Variables Numéricas:\n",
    "- Curricular units 1st sem (grade)\n",
    "- Curricular units 2nd sem (grade)\n",
    "- Curricular units 1st sem (approved)\n",
    "- Curricular units 2nd sem (approved)\n",
    "- Age at enrollment\n",
    "- GDP\n",
    "- Unemployment rate\n",
    "### Variables Categóricas (One-Hot Encoded):\n",
    "- Previous qualification\n",
    "- Scholarship holder\n",
    "- Displaced\n",
    "- Educational special needs\n",
    "- Course\n",
    "- Daytime/evening attendance\n",
    "- Tuition fees up to date\n",
    "## 11. Conclusiones del EDA\n",
    "1. Distribución de Clases :\n",
    "   \n",
    "   - Existe un desbalance moderado entre las clases\n",
    "   - Se recomienda considerar técnicas de balanceo\n",
    "2. Correlaciones Importantes :\n",
    "   \n",
    "   - Alta correlación entre notas de diferentes semestres\n",
    "   - Relación significativa entre unidades aprobadas y calificaciones\n",
    "3. Variables Predictivas Clave :\n",
    "   \n",
    "   - Las calificaciones son los mejores predictores\n",
    "   - Factores socioeconómicos muestran influencia moderada\n",
    "   - Variables categóricas aportan información valiosa sobre el perfil del estudiante\n",
    "4. Recomendaciones para Modelado :\n",
    "   \n",
    "   - Usar técnicas de balanceo de clases\n",
    "   - Considerar interacciones entre variables académicas\n",
    "   - Mantener todas las variables seleccionadas\n",
    "   - Evaluar modelos con validación cruzada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
